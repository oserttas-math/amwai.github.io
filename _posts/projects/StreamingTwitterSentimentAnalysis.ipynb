{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Sentiment Analysis of Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In a previous post, I demonstrated how one can go about building a text classification model for sentiment analysis. In this post, I will be applying the model previously developed to extract real-time sentiments of twitter data based on a search term.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "**Social media has become a valuable tool for anyone hoping to understand public sentiment on any current topic. Social media platforms such as Twitter, Facebook, and Instagram can provide a unique and unfiltered glimpse to what a target demographic has to say about a topic or product. Whether it is a campaign manager, social activist, or company brand manager, being able to monitor public sentiment in real-time means that one can quickly react to events. In this post, I will be applying a text classification model to twitter data using the streaming API to obtain real-time sentiment on a topic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re #for regex\n",
    "import pickle\n",
    "import dill\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "import MySQLdb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import processtweet\n",
    "import credentials as credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TweetStreamListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This class handles the tweets received from the stream\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tweets, conn, api=None):\n",
    "        self.num_tweets = num_tweets\n",
    "        self.textProcessing = processtweet.text_processing()\n",
    "        self.conn = conn\n",
    "        self.cursor = self.conn.cursor()\n",
    "        \n",
    "        #Check if the tables we need already exist in the MySQL db\n",
    "        #and if they do drop them and recreate the tables\n",
    "        self.cursor.execute(\"DROP TABLE IF EXISTS TwitterData CASCADE\")\n",
    "        self.cursor.execute(\"DROP TABLE IF EXISTS TwitterTrend CASCADE\")\n",
    "        self.cursor.execute(\"DROP TABLE IF EXISTS TwitterCurrent CASCADE\")\n",
    "        self.cursor.execute(\"CREATE TABLE TwitterData (id SERIAL PRIMARY KEY, Sentiment INT(1),\"\n",
    "                             \"DateTime VARCHAR(20), Tokens TEXT, Tweet VARCHAR(200))\")\n",
    "        self.cursor.execute(\"CREATE TABLE TwitterTrend (id SERIAL PRIMARY KEY,\"\n",
    "                            \"Pos_Sentiment VARCHAR(400), Neg_Sentiment VARCHAR(400), DateTime VARCHAR(40))\")\n",
    "        self.cursor.execute(\"CREATE TABLE TwitterCurrent (id SERIAL PRIMARY KEY, Pos VARCHAR(40), Neg VARCHAR(40),\"\n",
    "                             \"DateTime VARCHAR(20))\")\n",
    "        \n",
    "        #Initiate variables, including the start time\n",
    "        self.start_time = datetime.datetime.utcnow()\n",
    "        self.start_time_long = self.start_time\n",
    "        self.pos_count = 0\n",
    "        self.neg_count = 0\n",
    "        self.count = 0\n",
    "        super(TweetStreamListener, self).__init__()\n",
    "\n",
    "    def on_status(self, status):\n",
    "        try:\n",
    "            tweet_aslist = []\n",
    "            tweet = status.text.encode(\"utf-8\")\n",
    "            \n",
    "            #Exclude retweets since they will skew results\n",
    "            if hasattr(tweet, 'retweeted_status') or 'RT @' in tweet: \n",
    "                return\n",
    "            else:\n",
    "                #Note: Tweepy returns a time object set to UTC time\n",
    "                #see: http://timbueno.com/\n",
    "                time_stamp = status.created_at \n",
    "                \n",
    "                #Convert tweet to a list of a string\n",
    "                tweet_aslist.append(tweet)\n",
    "                \n",
    "                #Obtain the sentiment on each tweet\n",
    "                sentiment = self.textProcessing.tweetClassifier(tweet_aslist)\n",
    "                \n",
    "                #Tokenize the tweet\n",
    "                token = self.textProcessing.getTokens(tweet)\n",
    "                \n",
    "                current_time = datetime.datetime.utcnow()\n",
    "                \n",
    "                #Push sentiments to array\n",
    "                if sentiment == 4:\n",
    "                    self.pos_count = self.pos_count + 1\n",
    "                else:\n",
    "                    self.neg_count = self.neg_count + 1\n",
    "                    \n",
    "                #Write tweet sentiment count and timestamp to TwitterCurrent table every 1 min\n",
    "                #The goal here is to capture the time-dependent twitter activity on a topic\n",
    "                if current_time - self.start_time_long > datetime.timedelta(seconds=60):\n",
    "                    self.start_time_long = current_time\n",
    "                    self.cursor.execute(\"INSERT INTO TwitterCurrent (Pos, Neg, DateTime) \"\n",
    "                                        \"VALUES (%s, %s, %s)\", (self.pos_count, self.neg_count, current_time,))\n",
    "                    self.pos_count = 0\n",
    "                    self.neg_count = 0\n",
    "                                        \n",
    "                #Get tweets every 1 second and make sure there is at least 4 tweets    \n",
    "                if current_time - self.start_time >  datetime.timedelta(seconds=1) and  self.count > 4:\n",
    "                    self.start_time = current_time\n",
    "                    \n",
    "                    #Get a count of the positive and negative sentiments from TwitterData table\n",
    "                    self.cursor.execute(\"SELECT COUNT(Sentiment) FROM TwitterData \"\n",
    "                                        \"WHERE Sentiment = 4\")\n",
    "                    count_pos = int(self.cursor.fetchone()[0]) * 1\n",
    "                    self.cursor.execute(\"SELECT COUNT(Sentiment) FROM TwitterData \"\n",
    "                                        \"WHERE Sentiment = 0\")\n",
    "                    count_neg = int(self.cursor.fetchone()[0]) * -1\n",
    "                    \n",
    "                    #Write to the TwitterTrend table\n",
    "                    self.cursor.execute(\"INSERT INTO TwitterTrend (Pos_Sentiment, Neg_Sentiment, DateTime) \"\n",
    "                                        \"VALUES (%s, %s, %s)\", (count_pos, count_neg, current_time,))\n",
    "                    print self.start_time, count_pos, count_neg\n",
    "\n",
    "                #If count is less than number of tweets, write data to db\n",
    "                if self.count < self.num_tweets:\n",
    "                    self.count += 1\n",
    "                    self.cursor.execute(\"INSERT INTO TwitterData (Sentiment, \"\n",
    "                            \"DateTime, Tokens, Tweet) VALUES (%s, %s, %s, %s)\", \n",
    "                            (sentiment, time_stamp, str(token), tweet,))\n",
    "                    self.conn.commit()\n",
    "                    return True\n",
    "                else:\n",
    "                    #Otherwise, delete oldest entry in db and enter new one\n",
    "                    self.cursor.execute(\"DELETE FROM TwitterData \"\n",
    "                                        \"WHERE id IN \"\n",
    "                                        \"(SELECT id FROM \"\n",
    "                                        \"(SELECT id, Tweet FROM TwitterData ORDER BY id ASC LIMIT 1) AS t)\")\n",
    "                    self.conn.commit()\n",
    "                    self.cursor.execute(\"INSERT INTO TwitterData (Sentiment, \"\n",
    "                            \"DateTime, Tokens, Tweet) VALUES (%s, %s, %s, %s)\",\n",
    "                            (sentiment, time_stamp, str(token), tweet))\n",
    "                    self.conn.commit()\n",
    "                    return True\n",
    "\n",
    "            return True\n",
    "\n",
    "        except: \n",
    "            e = sys.exc_info()[0]\n",
    "            write_to_page( \"<p>Error: %s</p>\" % e )\n",
    "\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "        if status_code == 420:\n",
    "\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class connect_API():\n",
    "\n",
    "    def __init__(self, num_tweets):\n",
    "        \"\"\"\n",
    "        Obtain twitter API authorization\n",
    "        \"\"\"\n",
    "        consumer_key = credentials.login['consumer_key']\n",
    "        consumer_secret = credentials.login['consumer_secret']\n",
    "        access_key = credentials.login['access_key']\n",
    "        access_secret = credentials.login['access_secret']\n",
    "\n",
    "        self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        self.auth.set_access_token(access_key, access_secret)\n",
    "        self.num_tweets = num_tweets\n",
    "\n",
    "\n",
    "    def stream_data(self, search_item, conn):\n",
    "        \"\"\"\n",
    "        Get twitter streaming data\n",
    "        \"\"\"\n",
    "        twitterStream = tweepy.Stream(self.auth,\n",
    "                listener=TweetStreamListener(num_tweets =\n",
    "                    self.num_tweets, conn=conn))\n",
    "        twitterStream.filter(track=[search_item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-13 19:07:05.217021 4 -1\n",
      "2016-10-13 19:07:06.276141 18 -3\n",
      "2016-10-13 19:07:07.326413 31 -8\n",
      "2016-10-13 19:07:08.407842 38 -12\n",
      "2016-10-13 19:07:09.417260 40 -15\n",
      "2016-10-13 19:07:10.718208 42 -16\n",
      "2016-10-13 19:07:11.841328 49 -17\n",
      "2016-10-13 19:07:13.591763 52 -19\n",
      "2016-10-13 19:07:14.716295 56 -20\n",
      "2016-10-13 19:07:16.759291 57 -20\n",
      "2016-10-13 19:07:17.819179 62 -21\n",
      "2016-10-13 19:07:18.825260 67 -22\n",
      "2016-10-13 19:07:19.991666 73 -22\n",
      "2016-10-13 19:07:20.991949 79 -24\n",
      "2016-10-13 19:07:22.352758 84 -27\n",
      "2016-10-13 19:07:23.710001 92 -30\n",
      "2016-10-13 19:07:24.769069 97 -31\n",
      "2016-10-13 19:07:26.201974 104 -32\n",
      "2016-10-13 19:07:27.218048 108 -34\n",
      "2016-10-13 19:07:28.271075 116 -37\n",
      "2016-10-13 19:07:29.451550 125 -37\n",
      "2016-10-13 19:07:30.536801 132 -40\n",
      "2016-10-13 19:07:31.579873 140 -42\n",
      "2016-10-13 19:07:32.694604 145 -45\n",
      "2016-10-13 19:07:33.742261 149 -45\n",
      "2016-10-13 19:07:34.907263 156 -47\n",
      "2016-10-13 19:07:36.057784 164 -49\n",
      "2016-10-13 19:07:37.154289 170 -50\n",
      "2016-10-13 19:07:38.436498 180 -50\n",
      "2016-10-13 19:07:39.595011 183 -50\n",
      "2016-10-13 19:07:40.616528 194 -51\n",
      "2016-10-13 19:07:42.505184 197 -53\n",
      "2016-10-13 19:07:43.569222 203 -54\n",
      "2016-10-13 19:07:44.656036 205 -57\n",
      "2016-10-13 19:07:45.686363 210 -61\n",
      "2016-10-13 19:07:46.968124 214 -62\n",
      "2016-10-13 19:07:48.489277 221 -62\n",
      "2016-10-13 19:07:49.674734 226 -63\n",
      "2016-10-13 19:07:50.768975 230 -63\n",
      "2016-10-13 19:07:51.810154 235 -63\n",
      "2016-10-13 19:07:52.998976 238 -66\n",
      "2016-10-13 19:07:54.115473 242 -67\n",
      "2016-10-13 19:07:55.187661 250 -72\n",
      "2016-10-13 19:07:56.261770 257 -74\n",
      "2016-10-13 19:07:57.639957 261 -74\n",
      "2016-10-13 19:07:58.684416 265 -76\n",
      "2016-10-13 19:08:00.096672 271 -78\n",
      "2016-10-13 19:08:01.349201 278 -79\n",
      "2016-10-13 19:08:02.374861 283 -79\n",
      "2016-10-13 19:08:03.507031 285 -80\n",
      "2016-10-13 19:08:04.581102 290 -82\n",
      "2016-10-13 19:08:05.741261 297 -86\n",
      "2016-10-13 19:08:06.761310 303 -89\n",
      "2016-10-13 19:08:07.808877 306 -91\n",
      "2016-10-13 19:08:08.814531 312 -93\n",
      "2016-10-13 19:08:09.972340 319 -95\n",
      "2016-10-13 19:08:11.172185 322 -99\n",
      "2016-10-13 19:08:12.741405 328 -100\n",
      "2016-10-13 19:08:13.788279 331 -102\n",
      "2016-10-13 19:08:14.861790 334 -102\n",
      "2016-10-13 19:08:15.959216 339 -103\n",
      "2016-10-13 19:08:16.971495 345 -104\n",
      "2016-10-13 19:08:18.015534 352 -108\n",
      "2016-10-13 19:08:19.844162 357 -109\n",
      "2016-10-13 19:08:20.854757 359 -110\n",
      "2016-10-13 19:08:22.010336 363 -111\n",
      "2016-10-13 19:08:23.670249 368 -114\n",
      "2016-10-13 19:08:24.791014 372 -114\n",
      "2016-10-13 19:08:25.791167 376 -116\n",
      "2016-10-13 19:08:27.319157 379 -118\n",
      "2016-10-13 19:08:28.451135 384 -120\n",
      "2016-10-13 19:08:29.493726 386 -121\n",
      "2016-10-13 19:08:30.759477 389 -123\n",
      "2016-10-13 19:08:32.018179 393 -124\n",
      "2016-10-13 19:08:33.154799 398 -124\n",
      "2016-10-13 19:08:34.156642 403 -125\n",
      "2016-10-13 19:08:35.170247 406 -125\n",
      "2016-10-13 19:08:36.244397 410 -127\n",
      "2016-10-13 19:08:37.529974 413 -127\n",
      "2016-10-13 19:08:38.576283 419 -129\n",
      "2016-10-13 19:08:39.701382 425 -130\n",
      "2016-10-13 19:08:40.806761 428 -131\n",
      "2016-10-13 19:08:41.808694 433 -132\n",
      "2016-10-13 19:08:43.153894"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #db connection credentials\n",
    "    host = credentials.database['host']\n",
    "    user = credentials.database['user']\n",
    "    passwd = credentials.database['passwd']\n",
    "    unix_socket = credentials.database['unix_socket']\n",
    "    db = credentials.database['db']\n",
    " \n",
    "    #num_tweets are the number of tweets\n",
    "    #to be written to db while search_item\n",
    "    #is the search item to send to the \n",
    "    #streaming API\n",
    "    num_tweets =  2000\n",
    "    search_item = \"obama\"\n",
    "    try:\n",
    "        conn = MySQLdb.connect(host = host, user = user, passwd = passwd, unix_socket = unix_socket, db = db)\n",
    "        run_streaming = connect_API(num_tweets)\n",
    "        run_streaming.stream_data(search_item, conn)\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e.__doc__)\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### <font color='Navy'>We can then use the matplotlib animation module to view real-time plots of the twitter data. This is discussed in the next post.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
